{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RADIUS=1, POINTS=8, PATCH_SIZE=16...\n",
      "Testing RADIUS=1, POINTS=8, PATCH_SIZE=20...\n",
      "Testing RADIUS=1, POINTS=8, PATCH_SIZE=24...\n",
      "Testing RADIUS=1, POINTS=8, PATCH_SIZE=32...\n",
      "Testing RADIUS=1, POINTS=16, PATCH_SIZE=16...\n",
      "Testing RADIUS=1, POINTS=16, PATCH_SIZE=20...\n",
      "Testing RADIUS=1, POINTS=16, PATCH_SIZE=24...\n",
      "Testing RADIUS=1, POINTS=16, PATCH_SIZE=32...\n",
      "Testing RADIUS=1, POINTS=24, PATCH_SIZE=16...\n",
      "Testing RADIUS=1, POINTS=24, PATCH_SIZE=20...\n",
      "Testing RADIUS=1, POINTS=24, PATCH_SIZE=24...\n",
      "Testing RADIUS=1, POINTS=24, PATCH_SIZE=32...\n",
      "Testing RADIUS=1, POINTS=32, PATCH_SIZE=16...\n",
      "Testing RADIUS=1, POINTS=32, PATCH_SIZE=20...\n",
      "Testing RADIUS=1, POINTS=32, PATCH_SIZE=24...\n",
      "Testing RADIUS=1, POINTS=32, PATCH_SIZE=32...\n",
      "Testing RADIUS=2, POINTS=8, PATCH_SIZE=16...\n",
      "Testing RADIUS=2, POINTS=8, PATCH_SIZE=20...\n",
      "Testing RADIUS=2, POINTS=8, PATCH_SIZE=24...\n",
      "Testing RADIUS=2, POINTS=8, PATCH_SIZE=32...\n",
      "Testing RADIUS=2, POINTS=16, PATCH_SIZE=16...\n",
      "Testing RADIUS=2, POINTS=16, PATCH_SIZE=20...\n",
      "Testing RADIUS=2, POINTS=16, PATCH_SIZE=24...\n",
      "Testing RADIUS=2, POINTS=16, PATCH_SIZE=32...\n",
      "Testing RADIUS=2, POINTS=24, PATCH_SIZE=16...\n",
      "Testing RADIUS=2, POINTS=24, PATCH_SIZE=20...\n",
      "Testing RADIUS=2, POINTS=24, PATCH_SIZE=24...\n",
      "Testing RADIUS=2, POINTS=24, PATCH_SIZE=32...\n",
      "Testing RADIUS=2, POINTS=32, PATCH_SIZE=16...\n",
      "Testing RADIUS=2, POINTS=32, PATCH_SIZE=20...\n",
      "Testing RADIUS=2, POINTS=32, PATCH_SIZE=24...\n",
      "Testing RADIUS=2, POINTS=32, PATCH_SIZE=32...\n",
      "Testing RADIUS=3, POINTS=8, PATCH_SIZE=16...\n",
      "Testing RADIUS=3, POINTS=8, PATCH_SIZE=20...\n",
      "Testing RADIUS=3, POINTS=8, PATCH_SIZE=24...\n",
      "Testing RADIUS=3, POINTS=8, PATCH_SIZE=32...\n",
      "Testing RADIUS=3, POINTS=16, PATCH_SIZE=16...\n",
      "Testing RADIUS=3, POINTS=16, PATCH_SIZE=20...\n",
      "Testing RADIUS=3, POINTS=16, PATCH_SIZE=24...\n",
      "Testing RADIUS=3, POINTS=16, PATCH_SIZE=32...\n",
      "Testing RADIUS=3, POINTS=24, PATCH_SIZE=16...\n",
      "Testing RADIUS=3, POINTS=24, PATCH_SIZE=20...\n",
      "Testing RADIUS=3, POINTS=24, PATCH_SIZE=24...\n",
      "Testing RADIUS=3, POINTS=24, PATCH_SIZE=32...\n",
      "Testing RADIUS=3, POINTS=32, PATCH_SIZE=16...\n",
      "Testing RADIUS=3, POINTS=32, PATCH_SIZE=20...\n",
      "Testing RADIUS=3, POINTS=32, PATCH_SIZE=24...\n",
      "Testing RADIUS=3, POINTS=32, PATCH_SIZE=32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doni/.local/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RADIUS=4, POINTS=8, PATCH_SIZE=16...\n",
      "Testing RADIUS=4, POINTS=8, PATCH_SIZE=20...\n",
      "Testing RADIUS=4, POINTS=8, PATCH_SIZE=24...\n",
      "Testing RADIUS=4, POINTS=8, PATCH_SIZE=32...\n",
      "Testing RADIUS=4, POINTS=16, PATCH_SIZE=16...\n",
      "Testing RADIUS=4, POINTS=16, PATCH_SIZE=20...\n",
      "Testing RADIUS=4, POINTS=16, PATCH_SIZE=24...\n",
      "Testing RADIUS=4, POINTS=16, PATCH_SIZE=32...\n",
      "Testing RADIUS=4, POINTS=24, PATCH_SIZE=16...\n",
      "Testing RADIUS=4, POINTS=24, PATCH_SIZE=20...\n",
      "Testing RADIUS=4, POINTS=24, PATCH_SIZE=24...\n",
      "Testing RADIUS=4, POINTS=24, PATCH_SIZE=32...\n",
      "Testing RADIUS=4, POINTS=32, PATCH_SIZE=16...\n",
      "Testing RADIUS=4, POINTS=32, PATCH_SIZE=20...\n",
      "Testing RADIUS=4, POINTS=32, PATCH_SIZE=24...\n",
      "Testing RADIUS=4, POINTS=32, PATCH_SIZE=32...\n",
      "\n",
      "Best combination:\n",
      "RADIUS=1, POINTS=8, PATCH_SIZE=32, Accuracy=0.8246\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import dlib\n",
    "import itertools\n",
    "from joblib import Parallel, delayed  # Import parallel processing\n",
    "\n",
    "# Load the Dlib facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Paths to datasets\n",
    "down_syndrome_path = 'downSyndrome'\n",
    "healthy_path = 'healty'\n",
    "\n",
    "# Size of patches around landmarks (to be varied)\n",
    "patch_sizes = [16, 20, 24, 32]\n",
    "\n",
    "# List of specific landmarks to extract patches from\n",
    "landmark_indices = [\n",
    "    36, 39, 42, 45, 27, 30, 33, 31, 35, 51, 48, 54, 57, 68  \n",
    "]\n",
    "\n",
    "# Check if the face is frontal by verifying symmetry\n",
    "def is_frontal_face(landmarks):\n",
    "    left_eye = np.mean(np.array(landmarks[36:42]), axis=0)\n",
    "    right_eye = np.mean(np.array(landmarks[42:48]), axis=0)\n",
    "    nose_tip = np.array(landmarks[30])\n",
    "\n",
    "    # Calculate distances for symmetry\n",
    "    eye_distance = np.linalg.norm(left_eye - right_eye)\n",
    "    nose_to_left_eye = np.linalg.norm(nose_tip - left_eye)\n",
    "    nose_to_right_eye = np.linalg.norm(nose_tip - right_eye)\n",
    "\n",
    "    # Symmetry check threshold\n",
    "    symmetry_threshold = 0.15 * eye_distance\n",
    "    return abs(nose_to_left_eye - nose_to_right_eye) < symmetry_threshold\n",
    "\n",
    "# Function to extract patches around specific landmarks\n",
    "def extract_patches(image, landmarks, indices, patch_size):\n",
    "    patches = []\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    for idx in indices:\n",
    "        (x, y) = landmarks[idx]\n",
    "        # Define the patch region\n",
    "        x_start = max(x - patch_size // 2, 0)\n",
    "        y_start = max(y - patch_size // 2, 0)\n",
    "        x_end = min(x + patch_size // 2, gray.shape[1])\n",
    "        y_end = min(y + patch_size // 2, gray.shape[0])\n",
    "\n",
    "        # Extract patch\n",
    "        patch = gray[y_start:y_end, x_start:x_end]\n",
    "        if patch.size > 0:\n",
    "            patches.append(patch)\n",
    "\n",
    "    return patches\n",
    "\n",
    "# Function to extract LBP features from patches\n",
    "def extract_lbp_from_patches(patches, radius, points, method):\n",
    "    lbp_features = []\n",
    "    for patch in patches:\n",
    "        lbp = local_binary_pattern(patch, points, radius, method)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, points + 3), range=(0, points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)  # Normalize the histogram\n",
    "        lbp_features.extend(hist)  # Add the LBP histogram to the feature set\n",
    "    return lbp_features\n",
    "\n",
    "# Function to get landmarks\n",
    "def get_landmarks(image_input):\n",
    "    if isinstance(image_input, str):\n",
    "        img = cv2.imread(image_input)\n",
    "    else:\n",
    "        img = image_input\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)]\n",
    "        \n",
    "        # Add the extra landmark at the midpoint between 21 and 22\n",
    "        midpoint_x = (points[21][0] + points[22][0]) // 2\n",
    "        midpoint_y = (points[21][1] + points[22][1]) // 2\n",
    "        points.append((midpoint_x, midpoint_y))\n",
    "        \n",
    "        # Check if the face is frontal\n",
    "        if is_frontal_face(points):\n",
    "            return points\n",
    "    return None\n",
    "\n",
    "# Function to crop face from image\n",
    "def crop_face(image, landmarks, padding_percentage=0.1):\n",
    "    min_x = min(landmarks, key=lambda x: x[0])[0]\n",
    "    max_x = max(landmarks, key=lambda x: x[0])[0]\n",
    "    min_y = min(landmarks, key=lambda x: x[1])[1]\n",
    "    max_y = max(landmarks, key=lambda x: x[1])[1]\n",
    "\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    max_dimension = max(width, height)\n",
    "\n",
    "    padding = int(max_dimension * padding_percentage)\n",
    "    center_x = (min_x + max_x) // 2\n",
    "    center_y = (min_y + max_y) // 2\n",
    "\n",
    "    available_left = min_x\n",
    "    available_right = image.shape[1] - max_x\n",
    "    available_top = min_y\n",
    "    available_bottom = image.shape[0] - max_y\n",
    "\n",
    "    if available_left >= padding and available_right >= padding and available_top >= padding and available_bottom >= padding:\n",
    "        actual_padding = padding\n",
    "    else:\n",
    "        actual_padding = min(available_left, available_right, available_top, available_bottom)\n",
    "\n",
    "    size = max_dimension + actual_padding * 2\n",
    "\n",
    "    new_min_x = max(center_x - size // 2, 0)\n",
    "    new_max_x = min(center_x + size // 2, image.shape[1])\n",
    "    new_min_y = max(center_y - size // 2, 0)\n",
    "    new_max_y = min(center_y + size // 2, image.shape[0])\n",
    "\n",
    "    cropped_image = image[new_min_y:new_max_y, new_min_x:new_max_x]\n",
    "    cropped_image_resized = cv2.resize(cropped_image, (300, 300))\n",
    "\n",
    "    return cropped_image_resized\n",
    "\n",
    "# Function to detect landmarks and extract LBP features from specified points\n",
    "def get_lbp_features(image, radius, points, method, patch_size):\n",
    "    # Get landmarks from the original image\n",
    "    landmarks = get_landmarks(image)\n",
    "    \n",
    "    if landmarks:\n",
    "        # Crop the face from the image based on detected landmarks\n",
    "        cropped_image = crop_face(image, landmarks)\n",
    "        \n",
    "        # Get landmarks again on the cropped image\n",
    "        cropped_landmarks = get_landmarks(cropped_image)  # Re-apply landmark detection to cropped image\n",
    "        \n",
    "        if cropped_landmarks:\n",
    "            # Extract patches from the cropped image using the new landmarks\n",
    "            patches = extract_patches(cropped_image, cropped_landmarks, landmark_indices, patch_size)\n",
    "            \n",
    "            # Extract LBP features from the patches\n",
    "            lbp_features = extract_lbp_from_patches(patches, radius, points, method)\n",
    "            return lbp_features\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Define ranges for RADIUS, POINTS, and PATCH_SIZE\n",
    "radii = [1, 2, 3, 4]\n",
    "points_per_radius = [8, 16, 24, 32]\n",
    "patch_sizes = [16, 20, 24, 32]\n",
    "method = 'uniform'\n",
    "\n",
    "# Store results for analysis\n",
    "results = []\n",
    "\n",
    "# Function to process each combination of parameters\n",
    "def process_combination(radius, points, patch_size):\n",
    "    print(f\"Testing RADIUS={radius}, POINTS={points}, PATCH_SIZE={patch_size}...\")\n",
    "    \n",
    "    # Collect LBP features for current settings\n",
    "    X = []\n",
    "    y = []\n",
    "    for path, label in [(down_syndrome_path, 1), (healthy_path, 0)]:\n",
    "        for img_file in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                lbp_features = get_lbp_features(img, radius, points, method, patch_size)\n",
    "                if lbp_features:\n",
    "                    X.append(lbp_features)\n",
    "                    y.append(label)\n",
    "\n",
    "    # Convert to numpy arrays and scale\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = np.nan_to_num(X)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    model = SVC(C=1, kernel='rbf', gamma='scale', probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return (radius, points, patch_size, accuracy)\n",
    "\n",
    "# Use Parallel from joblib to run the combinations in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(process_combination)(radius, points, patch_size)\n",
    "                               for radius, points, patch_size in itertools.product(radii, points_per_radius, patch_sizes))\n",
    "\n",
    "# Find the best combination\n",
    "best_combination = max(results, key=lambda x: x[3])\n",
    "print(\"\\nBest combination:\")\n",
    "print(f\"RADIUS={best_combination[0]}, POINTS={best_combination[1]}, PATCH_SIZE={best_combination[2]}, Accuracy={best_combination[3]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
