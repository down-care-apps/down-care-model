{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the Dlib facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Paths to datasets\n",
    "down_syndrome_path = 'downSyndrome'\n",
    "healthy_path = 'healty'\n",
    "\n",
    "# Constants for LBP\n",
    "RADIUS = 2\n",
    "POINTS = 8 * RADIUS\n",
    "METHOD = 'uniform'\n",
    "\n",
    "# Size of patches around landmarks\n",
    "PATCH_SIZE = 16\n",
    "\n",
    "# List of specific landmarks to extract patches from\n",
    "landmark_indices = [\n",
    "    36, 39, 42, 45, 27, 30, 33, 31, 35, 51, 48, 54, 57, 68\n",
    "]\n",
    "\n",
    "# Define landmark pairs for geometric features\n",
    "pairs = [\n",
    "    (36, 39), (39, 42), (42, 45), (27, 30), (30, 33), (33, 31),\n",
    "    (33, 35), (30, 31), (30, 35), (33, 51), (51, 48), (51, 54),\n",
    "    (51, 57), (48, 57), (54, 57), (39, 68), (42, 68)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the face is frontal by verifying symmetry\n",
    "def is_frontal_face(landmarks):\n",
    "    left_eye = np.mean(np.array(landmarks[36:42]), axis=0)\n",
    "    right_eye = np.mean(np.array(landmarks[42:48]), axis=0)\n",
    "    nose_tip = np.array(landmarks[30])\n",
    "    eye_distance = np.linalg.norm(left_eye - right_eye)\n",
    "    nose_to_left_eye = np.linalg.norm(nose_tip - left_eye)\n",
    "    nose_to_right_eye = np.linalg.norm(nose_tip - right_eye)\n",
    "    symmetry_threshold = 0.15 * eye_distance\n",
    "    return abs(nose_to_left_eye - nose_to_right_eye) < symmetry_threshold\n",
    "\n",
    "# Modified function to get landmarks and add the 69th point\n",
    "def get_landmarks(image_input):\n",
    "    if isinstance(image_input, str):\n",
    "        img = cv2.imread(image_input)\n",
    "    else:\n",
    "        img = image_input\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)]\n",
    "        midpoint_x = (points[21][0] + points[22][0]) // 2\n",
    "        midpoint_y = (points[21][1] + points[22][1]) // 2\n",
    "        points.append((midpoint_x, midpoint_y))\n",
    "        if is_frontal_face(points):\n",
    "            return points\n",
    "    return None\n",
    "\n",
    "# Improved data augmentation function\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    # Flip horizontally\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    # Rotation\n",
    "    rows, cols = image.shape[:2]\n",
    "    for angle in [-15, -10, 0, 10, 15]:\n",
    "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "        augmented_images.append(cv2.warpAffine(image, M, (cols, rows)))\n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0, 10, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    augmented_images.append(noisy_image)\n",
    "    return augmented_images\n",
    "\n",
    "# Function to extract patches around specific landmarks\n",
    "def extract_patches(image, landmarks, indices, patch_size=PATCH_SIZE):\n",
    "    patches = []\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    for idx in indices:\n",
    "        (x, y) = landmarks[idx]\n",
    "        x_start = max(x - patch_size // 2, 0)\n",
    "        y_start = max(y - patch_size // 2, 0)\n",
    "        x_end = min(x + patch_size // 2, gray.shape[1])\n",
    "        y_end = min(y + patch_size // 2, gray.shape[0])\n",
    "        patch = gray[y_start:y_end, x_start:x_end]\n",
    "        if patch.size > 0:\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "# Function to extract LBP features from patches\n",
    "def extract_lbp_from_patches(patches, radius=RADIUS, points=POINTS, method=METHOD):\n",
    "    lbp_features = []\n",
    "    for patch in patches:\n",
    "        lbp = local_binary_pattern(patch, points, radius, method)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, points + 3), range=(0, points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        lbp_features.extend(hist)\n",
    "    return lbp_features\n",
    "\n",
    "# Function to extract geometric features from specific landmark pairs\n",
    "def extract_geometric_features(landmarks, pairs):\n",
    "    geom_features = []\n",
    "    for i, j in pairs:\n",
    "        p1 = landmarks[i]\n",
    "        p2 = landmarks[j]\n",
    "        distance = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "        geom_features.append(distance)\n",
    "    return geom_features\n",
    "\n",
    "# Function to extract combined features (LBP + Geometric)\n",
    "def get_combined_features(image, pairs):\n",
    "    landmarks = get_landmarks(image)\n",
    "    if landmarks:\n",
    "        patches = extract_patches(image, landmarks, landmark_indices)\n",
    "        lbp_features = extract_lbp_from_patches(patches)\n",
    "        geom_features = extract_geometric_features(landmarks, pairs)\n",
    "        combined_features = lbp_features + geom_features\n",
    "        return combined_features\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for path, label in [(down_syndrome_path, 1), (healthy_path, 0)]:\n",
    "    for img_file in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            combined_features = get_combined_features(img, pairs)\n",
    "            if combined_features:\n",
    "                X.append(combined_features)\n",
    "                y.append(label)\n",
    "                \n",
    "                # Apply data augmentation and extract features\n",
    "                augmented_images = augment_image(img)\n",
    "                for aug_img in augmented_images:\n",
    "                    aug_features = get_combined_features(aug_img, pairs)\n",
    "                    if aug_features:\n",
    "                        X.append(aug_features)\n",
    "                        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Handle NaNs and scale features\n",
    "X = np.nan_to_num(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reduce dimensionality using PCA\n",
    "pca = PCA(n_components=50)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 5.06 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,  \n",
    "    max_depth=None,    \n",
    "    random_state=42,   \n",
    "    class_weight=\"balanced\"  \n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "import time\n",
    "\n",
    "start_time = time.time() \n",
    "model.fit(X_train, y_train)  \n",
    "end_time = time.time() \n",
    "\n",
    "training_time = end_time - start_time  \n",
    "print(f\"Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Accuracy: 0.89\n",
      "Test Accuracy: 0.91\n",
      "Test Precision: 0.93\n",
      "Test Recall: 0.85\n",
      "Test AUC: 0.97\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1454\n",
      "           1       0.93      0.85      0.89      1196\n",
      "\n",
      "    accuracy                           0.91      2650\n",
      "   macro avg       0.91      0.90      0.90      2650\n",
      "weighted avg       0.91      0.91      0.90      2650\n",
      "\n",
      "Training Accuracy: 1.00\n",
      "Training Precision: 1.00\n",
      "Training Recall: 1.00\n",
      "Training AUC: 1.00\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3365\n",
      "           1       1.00      1.00      1.00      2818\n",
      "\n",
      "    accuracy                           1.00      6183\n",
      "   macro avg       1.00      1.00      1.00      6183\n",
      "weighted avg       1.00      1.00      1.00      6183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"5-Fold Cross-Validation Accuracy: {np.mean(cv_scores):.2f}\")\n",
    "# Evaluate on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_prob_test = model.predict_proba(X_test)[:, 1]  # Probabilities for AUC calculation\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "auc_test = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test:.2f}\")\n",
    "print(f\"Test Precision: {precision_test:.2f}\")\n",
    "print(f\"Test Recall: {recall_test:.2f}\")\n",
    "print(f\"Test AUC: {auc_test:.2f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_prob_train = model.predict_proba(X_train)[:, 1]  # Probabilities for AUC calculation\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "auc_train = roc_auc_score(y_train, y_prob_train)\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_train:.2f}\")\n",
    "print(f\"Training Precision: {precision_train:.2f}\")\n",
    "print(f\"Training Recall: {recall_train:.2f}\")\n",
    "print(f\"Training AUC: {auc_train:.2f}\")\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scaler saved to 'rf_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'pca': pca \n",
    "}\n",
    "joblib.dump(model_data, 'rf_model.pkl')\n",
    "\n",
    "\n",
    "print(\"Model and scaler saved to 'rf_model.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
