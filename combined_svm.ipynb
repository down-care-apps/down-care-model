{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 15:58:36.089057: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-04 15:58:36.092212: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-04 15:58:36.166553: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-04 15:58:36.206286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733302716.302974   13428 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733302716.341431   13428 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-04 15:58:36.516443: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# Load Dlib facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Paths to datasets\n",
    "down_syndrome_path = 'downSyndrome'\n",
    "healthy_path = 'healty'\n",
    "\n",
    "# Constants\n",
    "RADIUS = 1\n",
    "POINTS = 8 * RADIUS\n",
    "METHOD = 'uniform'\n",
    "PATCH_SIZE = 32\n",
    "\n",
    "landmark_indices = [36, 39, 42, 45, 27, 30, 33, 31, 35, 51, 48, 54, 57, 68]\n",
    "\n",
    "pairs = [\n",
    "    (36, 39), (39, 42), (42, 45), (27, 30), (30, 33), (33, 31),\n",
    "    (33, 35), (30, 31), (30, 35), (33, 51), (51, 48), (51, 54),\n",
    "    (51, 57), (48, 57), (54, 57), (39, 68), (42, 68)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_frontal_face(landmarks):\n",
    "    left_eye = np.mean(np.array(landmarks[36:42]), axis=0)\n",
    "    right_eye = np.mean(np.array(landmarks[42:48]), axis=0)\n",
    "    nose_tip = np.array(landmarks[30])\n",
    "    eye_distance = np.linalg.norm(left_eye - right_eye)\n",
    "    nose_to_left_eye = np.linalg.norm(nose_tip - left_eye)\n",
    "    nose_to_right_eye = np.linalg.norm(nose_tip - right_eye)\n",
    "    symmetry_threshold = 0.3 * eye_distance\n",
    "    return abs(nose_to_left_eye - nose_to_right_eye) < symmetry_threshold\n",
    "\n",
    "def get_landmarks(image_input):\n",
    "    gray = cv2.cvtColor(image_input, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)]\n",
    "        midpoint_x = (points[21][0] + points[22][0]) // 2\n",
    "        midpoint_y = (points[21][1] + points[22][1]) // 2\n",
    "        points.append((midpoint_x, midpoint_y))\n",
    "        # if is_frontal_face(points):\n",
    "        return points\n",
    "    return None\n",
    "\n",
    "def crop_face(image, landmarks, padding_percentage=0.1):\n",
    "    min_x = min(landmarks, key=lambda x: x[0])[0]\n",
    "    max_x = max(landmarks, key=lambda x: x[0])[0]\n",
    "    min_y = min(landmarks, key=lambda x: x[1])[1]\n",
    "    max_y = max(landmarks, key=lambda x: x[1])[1]\n",
    "\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    max_dimension = max(width, height)\n",
    "\n",
    "    padding = int(max_dimension * padding_percentage)\n",
    "    center_x = (min_x + max_x) // 2\n",
    "    center_y = (min_y + max_y) // 2\n",
    "\n",
    "    available_left = min_x\n",
    "    available_right = image.shape[1] - max_x\n",
    "    available_top = min_y\n",
    "    available_bottom = image.shape[0] - max_y\n",
    "\n",
    "    if available_left >= padding and available_right >= padding and available_top >= padding and available_bottom >= padding:\n",
    "        actual_padding = padding\n",
    "    else:\n",
    "        actual_padding = min(available_left, available_right, available_top, available_bottom)\n",
    "\n",
    "    size = max_dimension + actual_padding * 2\n",
    "\n",
    "    new_min_x = max(int(center_x - size // 2), 0)\n",
    "    new_max_x = min(int(center_x + size // 2), image.shape[1])\n",
    "    new_min_y = max(int(center_y - size // 2), 0)\n",
    "    new_max_y = min(int(center_y + size // 2), image.shape[0])\n",
    "\n",
    "    cropped_image = image[new_min_y:new_max_y, new_min_x:new_max_x]\n",
    "    cropped_image_resized = cv2.resize(cropped_image, (300, 300))\n",
    "\n",
    "    return cropped_image_resized\n",
    "\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "\n",
    "    # Flip horizontally\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    \n",
    "    rows, cols = image.shape[:2]\n",
    "\n",
    "    # Rotate images\n",
    "    for angle in [-15, -10, 0, 10, 15]:\n",
    "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "        rotated = cv2.warpAffine(image, M, (cols, rows))\n",
    "        augmented_images.append(rotated)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0, 10, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    augmented_images.append(noisy_image)\n",
    "\n",
    "    # Adjust brightness and contrast\n",
    "    for alpha in [0.8, 1.2]:  # Brightness scaling\n",
    "        brightened = cv2.convertScaleAbs(image, alpha=alpha, beta=0)\n",
    "        augmented_images.append(brightened)\n",
    "\n",
    "    # Sharpen the image\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(image, -1, kernel)\n",
    "    augmented_images.append(sharpened)\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "def extract_patches(image, landmarks, indices, patch_size=PATCH_SIZE):\n",
    "    patches = []\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    for idx in indices:\n",
    "        (x, y) = landmarks[idx]\n",
    "        x_start = max(x - patch_size // 2, 0)\n",
    "        y_start = max(y - patch_size // 2, 0)\n",
    "        x_end = min(x + patch_size // 2, gray.shape[1])\n",
    "        y_end = min(y + patch_size // 2, gray.shape[0])\n",
    "        patch = gray[y_start:y_end, x_start:x_end]\n",
    "        if patch.size > 0:\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def extract_lbp_from_patches(patches, radius=RADIUS, points=POINTS, method=METHOD):\n",
    "    lbp_features = []\n",
    "    for patch in patches:\n",
    "        lbp = local_binary_pattern(patch, points, radius, method)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, points + 3), range=(0, points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        lbp_features.extend(hist)\n",
    "    return lbp_features\n",
    "\n",
    "def extract_geometric_features(landmarks, pairs):\n",
    "    geom_features = []\n",
    "    for i, j in pairs:\n",
    "        p1 = landmarks[i]\n",
    "        p2 = landmarks[j]\n",
    "        distance = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "        geom_features.append(distance)\n",
    "    return geom_features\n",
    "\n",
    "def get_combined_features(image, pairs):\n",
    "    landmarks = get_landmarks(image)\n",
    "    if landmarks:\n",
    "        cropped_image = crop_face(image, landmarks)\n",
    "        cropped_landmarks = get_landmarks(cropped_image)\n",
    "        if cropped_landmarks:\n",
    "            patches = extract_patches(cropped_image, cropped_landmarks, landmark_indices)\n",
    "            lbp_features = extract_lbp_from_patches(patches)\n",
    "            geom_features = extract_geometric_features(cropped_landmarks, pairs)\n",
    "            return lbp_features + geom_features\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data\n",
    "X = []\n",
    "y = []\n",
    "fixed_feature_size = None  # Initialize the fixed size\n",
    "\n",
    "for path, label in [(down_syndrome_path, 1), (healthy_path, 0)]:\n",
    "    for img_file in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            combined_features = get_combined_features(img, pairs)\n",
    "            if combined_features:\n",
    "                # Initialize fixed size based on the first feature\n",
    "                if fixed_feature_size is None:\n",
    "                    fixed_feature_size = len(combined_features)\n",
    "\n",
    "                # Add features to the dataset\n",
    "                X.append(combined_features)\n",
    "                y.append(label)\n",
    "\n",
    "                # Apply data augmentation\n",
    "                augmented_images = augment_image(img)\n",
    "                for aug_img in augmented_images:\n",
    "                    aug_features = get_combined_features(aug_img, pairs)\n",
    "                    if aug_features:\n",
    "                        X.append(aug_features)\n",
    "                        y.append(label)\n",
    "\n",
    "# Ensure consistency in feature sizes\n",
    "def pad_or_truncate(features, fixed_size):\n",
    "    if len(features) > fixed_size:\n",
    "        return features[:fixed_size]  # Truncate\n",
    "    else:\n",
    "        return np.pad(features, (0, fixed_size - len(features)), mode='constant')  # Pad\n",
    "\n",
    "X = [pad_or_truncate(features, fixed_feature_size) for features in X]  # Fix feature sizes\n",
    "X = np.array(X)  # Convert to a NumPy array\n",
    "y = np.array(y)  # Convert labels to a NumPy array\n",
    "\n",
    "# Handle NaNs and scale features\n",
    "X = np.nan_to_num(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dimensionality reduction (optional)\n",
    "# pca = PCA(n_components=70)\n",
    "# X = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dimensionality reduction (optional)\n",
    "# pca = PCA(n_components=80)\n",
    "# X = pca.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 65.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with the best parameters found\n",
    "model = SVC(C=0.5, class_weight='balanced', gamma='auto', kernel='rbf', probability=True)\n",
    "\n",
    "# Train the model with the training data\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Accuracy: 0.89\n",
      "Test Accuracy: 0.89\n",
      "Test Precision: 0.88\n",
      "Test Recall: 0.90\n",
      "Test AUC: 0.96\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      2484\n",
      "           1       0.88      0.90      0.89      2224\n",
      "\n",
      "    accuracy                           0.89      4708\n",
      "   macro avg       0.89      0.89      0.89      4708\n",
      "weighted avg       0.89      0.89      0.89      4708\n",
      "\n",
      "Training Accuracy: 0.92\n",
      "Training Precision: 0.91\n",
      "Training Recall: 0.93\n",
      "Training AUC: 0.97\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      5758\n",
      "           1       0.91      0.93      0.92      5226\n",
      "\n",
      "    accuracy                           0.92     10984\n",
      "   macro avg       0.92      0.92      0.92     10984\n",
      "weighted avg       0.92      0.92      0.92     10984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"5-Fold Cross-Validation Accuracy: {np.mean(cv_scores):.2f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "auc_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test:.2f}\")\n",
    "print(f\"Test Precision: {precision_test:.2f}\")\n",
    "print(f\"Test Recall: {recall_test:.2f}\")\n",
    "print(f\"Test AUC: {auc_test:.2f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_pred_train = model.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "auc_train = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_train:.2f}\")\n",
    "print(f\"Training Precision: {precision_train:.2f}\")\n",
    "print(f\"Training Recall: {recall_train:.2f}\")\n",
    "print(f\"Training AUC: {auc_train:.2f}\")\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to trained_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Combine scaler, PCA, and model into a single dictionary\n",
    "model_pipeline = {\n",
    "    'scaler': scaler,\n",
    "    'model': model,\n",
    "    # 'pca' : pca\n",
    "}\n",
    "\n",
    "# Save to a .pkl file\n",
    "with open('trained_model_v5.pkl', 'wb') as file:\n",
    "    pickle.dump(model_pipeline, file)\n",
    "\n",
    "print(\"Model saved successfully to trained_model.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
