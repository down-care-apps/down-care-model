{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "down_syndrome_path = 'downSyndrome'\n",
    "healthy_path = 'healty'\n",
    "\n",
    "RADIUS = 1\n",
    "POINTS = 8 * RADIUS\n",
    "METHOD = 'uniform'\n",
    "PATCH_SIZE = 32\n",
    "\n",
    "landmark_indices = [36, 39, 42, 45, 27, 30, 33, 31, 35, 51, 48, 54, 57, 68]\n",
    "\n",
    "pairs = [\n",
    "    (36, 39), (39, 42), (42, 45), (27, 30), (30, 33), (33, 31),\n",
    "    (33, 35), (30, 31), (30, 35), (33, 51), (51, 48), (51, 54),\n",
    "    (51, 57), (48, 57), (54, 57), (39, 68), (42, 68)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_frontal_face(landmarks):\n",
    "    left_eye = np.mean(np.array(landmarks[36:42]), axis=0)\n",
    "    right_eye = np.mean(np.array(landmarks[42:48]), axis=0)\n",
    "    nose_tip = np.array(landmarks[30])\n",
    "    eye_distance = np.linalg.norm(left_eye - right_eye)\n",
    "    nose_to_left_eye = np.linalg.norm(nose_tip - left_eye)\n",
    "    nose_to_right_eye = np.linalg.norm(nose_tip - right_eye)\n",
    "    symmetry_threshold = 0.3 * eye_distance\n",
    "    return abs(nose_to_left_eye - nose_to_right_eye) < symmetry_threshold\n",
    "\n",
    "def get_landmarks(image_input):\n",
    "    gray = cv2.cvtColor(image_input, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)]\n",
    "        midpoint_x = (points[21][0] + points[22][0]) // 2\n",
    "        midpoint_y = (points[21][1] + points[22][1]) // 2\n",
    "        points.append((midpoint_x, midpoint_y))\n",
    "        if is_frontal_face(points):\n",
    "            return points\n",
    "    return None\n",
    "\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    augmented_images.append(cv2.flip(image, 1))  # Flip horizontally\n",
    "    rows, cols = image.shape[:2]\n",
    "    for angle in [-15, -10, 0, 10, 15]:  # Rotate\n",
    "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "        augmented_images.append(cv2.warpAffine(image, M, (cols, rows)))\n",
    "    noise = np.random.normal(0, 10, image.shape).astype(np.uint8)  # Add Gaussian noise\n",
    "    augmented_images.append(cv2.add(image, noise))\n",
    "    return augmented_images\n",
    "\n",
    "def extract_patches(image, landmarks, indices, patch_size=PATCH_SIZE):\n",
    "    patches = []\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    for idx in indices:\n",
    "        (x, y) = landmarks[idx]\n",
    "        x_start = max(x - patch_size // 2, 0)\n",
    "        y_start = max(y - patch_size // 2, 0)\n",
    "        x_end = min(x + patch_size // 2, gray.shape[1])\n",
    "        y_end = min(y + patch_size // 2, gray.shape[0])\n",
    "        patch = gray[y_start:y_end, x_start:x_end]\n",
    "        if patch.size > 0:\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def extract_lbp_from_patches(patches, radius=RADIUS, points=POINTS, method=METHOD):\n",
    "    lbp_features = []\n",
    "    for patch in patches:\n",
    "        lbp = local_binary_pattern(patch, points, radius, method)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, points + 3), range=(0, points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        lbp_features.extend(hist)\n",
    "    return lbp_features\n",
    "\n",
    "def extract_geometric_features(landmarks, pairs):\n",
    "    geom_features = []\n",
    "    for i, j in pairs:\n",
    "        p1 = landmarks[i]\n",
    "        p2 = landmarks[j]\n",
    "        distance = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "        geom_features.append(distance)\n",
    "    return geom_features\n",
    "\n",
    "def align_face(image, landmarks):\n",
    "    if landmarks is None or len(landmarks) < 68:\n",
    "        raise ValueError(\"Landmarks are invalid or incomplete.\")\n",
    "    \n",
    "    # Convert landmarks to numpy array\n",
    "    landmarks = np.array(landmarks, dtype=np.float32)\n",
    "\n",
    "    # Calculate the center of the left and right eyes\n",
    "    left_eye_center = np.mean(landmarks[36:42], axis=0)\n",
    "    right_eye_center = np.mean(landmarks[42:48], axis=0)\n",
    "\n",
    "    # Calculate the angle between the eye centers\n",
    "    dy = right_eye_center[1] - left_eye_center[1]\n",
    "    dx = right_eye_center[0] - left_eye_center[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "    # Calculate the center point between the two eyes\n",
    "    eye_center = tuple(np.mean([left_eye_center, right_eye_center], axis=0))\n",
    "\n",
    "    # Get the rotation matrix for the alignment\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, scale=1.0)\n",
    "\n",
    "    # Perform the alignment\n",
    "    aligned_image = cv2.warpAffine(\n",
    "        image, \n",
    "        rotation_matrix, \n",
    "        (image.shape[1], image.shape[0]),\n",
    "        flags=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    # Transform the landmarks to match the aligned image\n",
    "    ones = np.ones((landmarks.shape[0], 1), dtype=np.float32)  # Homogeneous coordinates\n",
    "    landmarks_hom = np.hstack([landmarks, ones])\n",
    "    transformed_landmarks = rotation_matrix @ landmarks_hom.T\n",
    "    transformed_landmarks = transformed_landmarks[:2].T  # Convert back to (x, y) format\n",
    "\n",
    "    return aligned_image, transformed_landmarks\n",
    "\n",
    "def crop_face(image, landmarks, padding_percentage=0.1):\n",
    "    min_x = min(landmarks, key=lambda x: x[0])[0]\n",
    "    max_x = max(landmarks, key=lambda x: x[0])[0]\n",
    "    min_y = min(landmarks, key=lambda x: x[1])[1]\n",
    "    max_y = max(landmarks, key=lambda x: x[1])[1]\n",
    "\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    max_dimension = max(width, height)\n",
    "\n",
    "    padding = int(max_dimension * padding_percentage)\n",
    "    center_x = (min_x + max_x) // 2\n",
    "    center_y = (min_y + max_y) // 2\n",
    "\n",
    "    available_left = min_x\n",
    "    available_right = image.shape[1] - max_x\n",
    "    available_top = min_y\n",
    "    available_bottom = image.shape[0] - max_y\n",
    "\n",
    "    if available_left >= padding and available_right >= padding and available_top >= padding and available_bottom >= padding:\n",
    "        actual_padding = padding\n",
    "    else:\n",
    "        actual_padding = min(available_left, available_right, available_top, available_bottom)\n",
    "\n",
    "    size = max_dimension + actual_padding * 2\n",
    "\n",
    "    new_min_x = max(int(center_x - size // 2), 0)\n",
    "    new_max_x = min(int(center_x + size // 2), image.shape[1])\n",
    "    new_min_y = max(int(center_y - size // 2), 0)\n",
    "    new_max_y = min(int(center_y + size // 2), image.shape[0])\n",
    "\n",
    "    cropped_image = image[new_min_y:new_max_y, new_min_x:new_max_x]\n",
    "    cropped_image_resized = cv2.resize(cropped_image, (300, 300))\n",
    "\n",
    "    return cropped_image_resized\n",
    "\n",
    "def get_combined_features(image, pairs):\n",
    "    landmarks = get_landmarks(image)\n",
    "    if landmarks is None or len(landmarks) < 68:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        aligned_image, aligned_landmarks = align_face(image, landmarks)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in alignment: {e}\")\n",
    "        return None\n",
    "\n",
    "    cropped_image = crop_face(aligned_image, aligned_landmarks)\n",
    "\n",
    "    cropped_landmarks = get_landmarks(cropped_image)\n",
    "    if cropped_landmarks is None or len(cropped_landmarks) < 68:\n",
    "        return None\n",
    "\n",
    "    patches = extract_patches(cropped_image, cropped_landmarks, landmark_indices)\n",
    "    lbp_features = extract_lbp_from_patches(patches)\n",
    "    geom_features = extract_geometric_features(cropped_landmarks, pairs)\n",
    "\n",
    "    lbp_array = np.array(lbp_features)\n",
    "    geom_array = np.array(geom_features)\n",
    "    combined_features = np.hstack([lbp_array, geom_array])\n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for path, label in [(down_syndrome_path, 1), (healthy_path, 0)]:\n",
    "    for img_file in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            combined_features = get_combined_features(img, pairs)\n",
    "            if combined_features is not None:\n",
    "                X.append(combined_features)\n",
    "                y.append(label)\n",
    "\n",
    "                # Apply data augmentation\n",
    "                augmented_images = augment_image(img)\n",
    "                for aug_img in augmented_images:\n",
    "                    aug_features = get_combined_features(aug_img, pairs)\n",
    "                    if aug_features is not None:\n",
    "                        X.append(aug_features)\n",
    "                        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all feature vectors have the same length\n",
    "max_length = max(len(features) for features in X)\n",
    "X_padded = [np.pad(features, (0, max_length - len(features)), 'constant') for features in X]\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(X_padded)\n",
    "y = np.array(y)\n",
    "\n",
    "# Handle NaNs and scale features\n",
    "X = np.nan_to_num(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# # Dimensionality reduction\n",
    "# pca = PCA(n_components=50)\n",
    "# X = pca.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 31.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = SVC(C=0.8, kernel='rbf', gamma='scale', probability=True, class_weight='balanced')\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Accuracy: 0.91\n",
      "Test Accuracy: 0.93\n",
      "Test Precision: 0.93\n",
      "Test Recall: 0.93\n",
      "Test AUC: 0.98\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1737\n",
      "           1       0.93      0.93      0.93      1650\n",
      "\n",
      "    accuracy                           0.93      3387\n",
      "   macro avg       0.93      0.93      0.93      3387\n",
      "weighted avg       0.93      0.93      0.93      3387\n",
      "\n",
      "Training Accuracy: 0.95\n",
      "Training Precision: 0.94\n",
      "Training Recall: 0.96\n",
      "Training AUC: 0.99\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      4163\n",
      "           1       0.94      0.96      0.95      3740\n",
      "\n",
      "    accuracy                           0.95      7903\n",
      "   macro avg       0.95      0.95      0.95      7903\n",
      "weighted avg       0.95      0.95      0.95      7903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"5-Fold Cross-Validation Accuracy: {np.mean(cv_scores):.2f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "auc_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test:.2f}\")\n",
    "print(f\"Test Precision: {precision_test:.2f}\")\n",
    "print(f\"Test Recall: {recall_test:.2f}\")\n",
    "print(f\"Test AUC: {auc_test:.2f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_pred_train = model.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "auc_train = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_train:.2f}\")\n",
    "print(f\"Training Precision: {precision_train:.2f}\")\n",
    "print(f\"Training Recall: {recall_train:.2f}\")\n",
    "print(f\"Training AUC: {auc_train:.2f}\")\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to trained_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "model_pipeline = {\n",
    "    'scaler': scaler,\n",
    "    'model': model,\n",
    "    # 'pca' : pca\n",
    "}\n",
    "\n",
    "with open('trained_model_v7.pkl', 'wb') as file:\n",
    "    pickle.dump(model_pipeline, file)\n",
    "\n",
    "print(\"Model saved successfully to trained_model.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
